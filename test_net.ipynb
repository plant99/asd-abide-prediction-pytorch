{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ehy tensor([[[[0.6549, 0.6549, 0.6549,  ..., 0.5412, 0.5412, 0.5412],\n",
      "          [0.6745, 0.6745, 0.6667,  ..., 0.5412, 0.5412, 0.5412],\n",
      "          [0.6627, 0.6667, 0.6627,  ..., 0.5412, 0.5412, 0.5412],\n",
      "          ...,\n",
      "          [0.6000, 0.5843, 0.5804,  ..., 0.4863, 0.4863, 0.4863],\n",
      "          [0.5922, 0.5804, 0.5804,  ..., 0.4863, 0.4863, 0.4863],\n",
      "          [0.5804, 0.5725, 0.5725,  ..., 0.4863, 0.4863, 0.4863]],\n",
      "\n",
      "         [[0.6863, 0.6824, 0.6784,  ..., 0.5373, 0.5373, 0.5373],\n",
      "          [0.7059, 0.7059, 0.6941,  ..., 0.5373, 0.5373, 0.5373],\n",
      "          [0.6980, 0.6980, 0.6941,  ..., 0.5373, 0.5373, 0.5373],\n",
      "          ...,\n",
      "          [0.6039, 0.5843, 0.5765,  ..., 0.4824, 0.4824, 0.4824],\n",
      "          [0.5961, 0.5804, 0.5765,  ..., 0.4824, 0.4824, 0.4824],\n",
      "          [0.5843, 0.5725, 0.5686,  ..., 0.4824, 0.4824, 0.4824]],\n",
      "\n",
      "         [[0.6431, 0.6510, 0.6627,  ..., 0.5569, 0.5569, 0.5569],\n",
      "          [0.6549, 0.6627, 0.6627,  ..., 0.5569, 0.5569, 0.5569],\n",
      "          [0.6314, 0.6392, 0.6431,  ..., 0.5569, 0.5569, 0.5569],\n",
      "          ...,\n",
      "          [0.5804, 0.5765, 0.5961,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          [0.5725, 0.5725, 0.5961,  ..., 0.5020, 0.5020, 0.5020],\n",
      "          [0.5608, 0.5647, 0.5882,  ..., 0.5020, 0.5020, 0.5020]]]]) tensor([0])\n",
      "tensor([[[0.6549, 0.6549, 0.6549,  ..., 0.5412, 0.5412, 0.5412],\n",
      "         [0.6745, 0.6745, 0.6667,  ..., 0.5412, 0.5412, 0.5412],\n",
      "         [0.6627, 0.6667, 0.6627,  ..., 0.5412, 0.5412, 0.5412],\n",
      "         ...,\n",
      "         [0.6000, 0.5843, 0.5804,  ..., 0.4863, 0.4863, 0.4863],\n",
      "         [0.5922, 0.5804, 0.5804,  ..., 0.4863, 0.4863, 0.4863],\n",
      "         [0.5804, 0.5725, 0.5725,  ..., 0.4863, 0.4863, 0.4863]],\n",
      "\n",
      "        [[0.6863, 0.6824, 0.6784,  ..., 0.5373, 0.5373, 0.5373],\n",
      "         [0.7059, 0.7059, 0.6941,  ..., 0.5373, 0.5373, 0.5373],\n",
      "         [0.6980, 0.6980, 0.6941,  ..., 0.5373, 0.5373, 0.5373],\n",
      "         ...,\n",
      "         [0.6039, 0.5843, 0.5765,  ..., 0.4824, 0.4824, 0.4824],\n",
      "         [0.5961, 0.5804, 0.5765,  ..., 0.4824, 0.4824, 0.4824],\n",
      "         [0.5843, 0.5725, 0.5686,  ..., 0.4824, 0.4824, 0.4824]],\n",
      "\n",
      "        [[0.6431, 0.6510, 0.6627,  ..., 0.5569, 0.5569, 0.5569],\n",
      "         [0.6549, 0.6627, 0.6627,  ..., 0.5569, 0.5569, 0.5569],\n",
      "         [0.6314, 0.6392, 0.6431,  ..., 0.5569, 0.5569, 0.5569],\n",
      "         ...,\n",
      "         [0.5804, 0.5765, 0.5961,  ..., 0.5020, 0.5020, 0.5020],\n",
      "         [0.5725, 0.5725, 0.5961,  ..., 0.5020, 0.5020, 0.5020],\n",
      "         [0.5608, 0.5647, 0.5882,  ..., 0.5020, 0.5020, 0.5020]]]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=4)\n",
    "        self.fc1 = nn.Linear(576, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "class CustomDatasetFromImages(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            img_path (string): path to the folder where images are\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        # Read the csv file\n",
    "#         self.data_info = pd.read_csv(csv_path, header=None)\n",
    "        # First column contains the image paths\n",
    "        self.image_arr = []\n",
    "        self.operation_arr = []\n",
    "        self.label_arr = []\n",
    "        for i, name in enumerate(os.listdir('./data/train')):\n",
    "            for j in os.listdir('./data/train/'+ name):\n",
    "                self.image_arr.append('./data/train/'+ name+'/'+j)\n",
    "                self.label_arr.append(i)\n",
    "                self.operation_arr.append(False)\n",
    "#                 print('./data/train/'+ i+'/'+j, str(i), False)\n",
    "                break\n",
    "            break\n",
    "#         self.image_arr = np.asarray('./data/train/'+self.data_info.iloc[:, 1]+'/'+self.data_info.iloc[:, 0])\n",
    "#         # Second column is the labels\n",
    "#         self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
    "#         # Third column is for an operation indicator\n",
    "#         self.operation_arr = np.asarray(self.data_info.iloc[:, 2])\n",
    "        # Calculate len\n",
    "        self.data_len = len(self.image_arr)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        try:\n",
    "            single_image_name = self.image_arr[index]\n",
    "            # Open image\n",
    "            img_as_img = Image.open(single_image_name)\n",
    "            img_as_img.convert('RGB')\n",
    "\n",
    "            # Check if there is an operation\n",
    "            some_operation = self.operation_arr[index]\n",
    "            # If there is an operation\n",
    "            if some_operation:\n",
    "                # Do some operation on image\n",
    "                # ...\n",
    "                # ...\n",
    "                pass\n",
    "            # Transform image to tensor\n",
    "            img_as_tensor = self.to_tensor(img_as_img)\n",
    "\n",
    "            # Get label(class) of the image based on the cropped pandas column\n",
    "            single_image_label = self.label_arr[index]\n",
    "\n",
    "            return (img_as_tensor, single_image_label)\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            return\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "\n",
    "# class CustomDatasetFromCSV(Dataset):\n",
    "#     def __init__(self, csv_path, height, width, transform=None):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             csv_path (string): path to csv file\n",
    "#             height (int): image height\n",
    "#             width (int): image width\n",
    "#             transform: pytorch transforms for transforms and tensor conversion\n",
    "#         \"\"\"\n",
    "#         self.data = pd.read_csv(csv_path)\n",
    "#         self.labels = np.asarray(self.data.iloc[:, 0])\n",
    "#         self.height = height\n",
    "#         self.width = width\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         single_image_label = self.labels[index]\n",
    "#         # Read each 784 pixels and reshape the 1D array ([784]) to 2D array ([28,28])\n",
    "#         img_as_np = np.asarray(self.data.iloc[index][1:]).reshape(28, 28).astype('uint8')\n",
    "#         # Convert image from numpy array to PIL image, mode 'L' is for grayscale\n",
    "#         img_as_img = Image.fromarray(img_as_np)\n",
    "#         img_as_img = img_as_img.convert('L')\n",
    "#         # Transform image to tensor\n",
    "#         if self.transform is not None:\n",
    "#             img_as_tensor = self.transform(img_as_img)\n",
    "#         # Return image and the label\n",
    "#         return (img_as_tensor, single_image_label)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data.index)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    transformations = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    custom_mnist_from_images =  \\\n",
    "        CustomDatasetFromImages('')\n",
    "\n",
    "#     custom_mnist_from_csv = \\\n",
    "#         CustomDatasetFromCSV('../data/mnist_in_csv.csv',\n",
    "#                              28, 28,\n",
    "#                              transformations)\n",
    "\n",
    "    mn_dataset_loader = torch.utils.data.DataLoader(dataset=custom_mnist_from_images,\n",
    "                                                    batch_size=10,\n",
    "                                                    shuffle=False)\n",
    "#     print(mn_dataset_loader)\n",
    "    model = CNNModel()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    print(len(mn_dataset_loader))\n",
    "    for i, (images, labels) in enumerate(mn_dataset_loader):\n",
    "        print(\"ehy\", images, labels)\n",
    "        images = Variable(images[0])\n",
    "        labels = Variable(labels[0])\n",
    "        print(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
